# ğŸ” Authenticity Detector

> **Advanced AI-powered system for detecting fake news and AI-generated content using Neo4j Graph Database and Large Language Models**

## ğŸ¯ Overview

The **Authenticity Detector** is a sophisticated system that combines graph databases, vector embeddings, and large language models to detect fake news and AI-generated content with high accuracy. Built for researchers, journalists, and content moderators who need reliable authenticity verification.

### ğŸ”¥ Key Features

- **ğŸ“° Fake News Detection**: Identify misinformation across political, health, and social topics
- **ğŸ¤– AI Content Detection**: Distinguish between human-written and AI-generated essays/articles  
- **ğŸ” Semantic Search**: Find similar content patterns using advanced vector embeddings
- **ğŸ“Š Pattern Analysis**: Discover trends in misinformation and AI content generation
- **ğŸ’¬ Interactive Chat**: Natural language queries powered by Groq and OpenAI
- **â˜ï¸ Cloud-Ready**: Works with Azure Neo4j Aura (no local database required)

## ğŸ—‚ï¸ Datasets

This project analyzes a comprehensive dataset named ai-ga data:
### ğŸ¤– LLM AI-Generated Text Dataset  
- **Source**: [Kaggle - LLM Detect AI Generated Text](https://www.kaggle.com/datasets/sunilthite/llm-detect-ai-generated-text-dataset)
- **Size**: ~28,000 essays
- **Content**: Student essays and AI-generated equivalents
- **Labels**: Human-written (0) vs AI-generated (1)
- **Features**: Essay text, generation label

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Neo4j Aura account (free tier available)
- OpenAI API key
- Groq API key

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/maksuranuha/authenticity-detector.git
cd authenticity-detector
```

2. **Set up virtual environment**
```bash
python -m venv env
# Windows:
env\Scripts\activate
# Mac/Linux:
source env/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

4. **Download datasets**
   - Download datasets from Kaggle links above
   - Place CSV files in `data/` folder:
     - `data/Fake.csv`
     - `data/True.csv` 
     - `data/AI_generated.csv`

5. **Configure environment**
```bash
# Create .env file
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
NEO4J_DATABASE=neo4j

OPENAI_API_KEY=sk-your-openai-key
GROQ_API_KEY=your-groq-key
GROQ_MODEL=mixtral-8x7b-32768
```

### ğŸƒâ€â™‚ï¸ Running the System

**Step 1: Load Data**
```bash
python optimized_loader.py
```
*Loads and processes 73,000+ articles/essays (~2-5 minutes)*

**Step 2: Generate Embeddings**
```bash
python optimized_embeddings.py
```
*Creates vector embeddings for similarity search (~10-20 minutes)*

**Step 3: Test Accuracy**
```bash
python test.py
```
*Validates system performance with real samples*

**Step 4: Launch Application**
```bash
streamlit run chatbot.py
```
*Opens web interface at `http://localhost:8501`*

## ğŸ’¡ Usage Examples

### Interactive Queries
```
"Show me fake news patterns in politics"
"Find AI-generated essays about technology"
"What are the most deceptive content topics?"
"Compare human vs AI writing styles"
"Find articles similar to election fraud claims"
```

### Programmatic Access
```python
from langchain_neo4j import Neo4jGraph

kg = Neo4jGraph(url=NEO4J_URI, username=USERNAME, password=PASSWORD)

# Find fake news by subject
result = kg.query("""
    MATCH (a:Article)-[:HAS_SUBJECT]->(s:Subject {name: "politics"})
    WHERE a.is_fake = true
    RETURN a.title, a.date
    ORDER BY a.date DESC LIMIT 10
""")
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   Processing    â”‚    â”‚   Analysis      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Fake News CSV â”‚â”€â”€â”€â–¶â”‚ â€¢ NLP Pipeline  â”‚â”€â”€â”€â–¶â”‚ â€¢ Graph Queries â”‚
â”‚ â€¢ Real News CSV â”‚    â”‚ â€¢ Keyword Ext.  â”‚    â”‚ â€¢ Vector Search â”‚
â”‚ â€¢ AI Essays CSV â”‚    â”‚ â€¢ Embeddings    â”‚    â”‚ â€¢ LLM Analysis  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Neo4j Graph   â”‚    â”‚   Vector Index  â”‚    â”‚   Streamlit UI  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Articles      â”‚â—€â”€â”€â”€â”‚ â€¢ Embeddings    â”‚â—€â”€â”€â”€â”‚ â€¢ Chat Interfaceâ”‚
â”‚ â€¢ Essays        â”‚    â”‚ â€¢ Similarity    â”‚    â”‚ â€¢ Visualizationsâ”‚
â”‚ â€¢ Relationships â”‚    â”‚ â€¢ Search        â”‚    â”‚ â€¢ Reports       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Key Components

### ğŸ”§ Core Modules

| Module | Purpose | Key Features |
|--------|---------|--------------|
| `optimized_loader.py` | Data ingestion | Enhanced NLP, deduplication, relationship mapping |
| `optimized_embeddings.py` | Vector generation | Context-aware embeddings, similarity indices |
| `chatbot.py` | User interface | Natural language queries, real-time analysis |
| `test.py` | Accuracy validation | Performance metrics, sample testing |

### ğŸ§  AI Models Used

- **OpenAI GPT-3.5/4**: Content classification and analysis
- **OpenAI text-embedding-3-small**: Semantic vector embeddings  
- **Groq Mixtral-8x7B**: Fast inference for chat responses
- **spaCy**: Advanced NLP for keyword extraction

### ğŸ“ˆ Graph Schema

```cypher
// News Articles
(Article)-[:HAS_SUBJECT]->(Subject)
(Article)-[:CONTAINS_KEYWORD]->(Keyword)

// Essays
(Essay)-[:CONTAINS_KEYWORD]->(Keyword)

// Properties
Article: {id, title, text, is_fake, date, embedding}
Essay: {id, title, text, generated, word_count, embedding}
Subject: {name}
Keyword: {name}
```

## ğŸ“‹ Requirements

```
neo4j
python-dotenv
pandas
numpy
langchain
langchain-openai
langchain-community
langchain-neo4j
langchain-groq
openai
streamlit
nltk
spacy
scikit-learn
tqdm
```

## ğŸš¢ Deployment

### Local Development
```bash
streamlit run chatbot.py
```

### Cloud Deployment (Streamlit Cloud)
1. Push to GitHub
2. Connect to Streamlit Cloud
3. Add environment variables
4. Deploy automatically

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š Research & References

- **Graph-Based Fake News Detection**: Leveraging relationship patterns
- **Vector Embeddings for Content Analysis**: Semantic similarity approaches
- **LLM-Based Classification**: Comparing human vs AI-generated text
- **Neo4j Vector Indexing**: Optimizing similarity search performance

**â­ If this project helps you, please give it a star!**